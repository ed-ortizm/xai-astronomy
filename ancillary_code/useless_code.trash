Code for processing explanation files
def analyze_explanation(self, exp_file_path: str, save=True):
    def process_array(self, spec, data_array):

        wave_exp = data_array[:, :, 1]
        weights_exp = data_array[:, :, 2]

        flx_exp = np.empty(wave_exp.shape)
        flx_exp[:] = np.nan

        for idx, flx in enumerate(flx_exp):
            # print(f"Iteration {idx}")
            index = [np.int(i) for i in wave_exp[idx] if not np.isnan(i)]
            print(f"Index length: {len(index)}")
            flx[index] = spec[index]
            print(np.count_nonzero(np.isnan(spec)))
            print(np.count_nonzero(np.isnan(flx)))

        return wave_exp, flx_exp, weights_exp
    def _get_arrays(self, exp_dict, arrays_names, sdss_name, metric,
        save=False):

        n_kernels = len(exp_dict)

        # dictionary to store the explanation data, where the identifiers will
        # will be the names of the arrays
        data_dict = {f"{array_name}":[] for array_name in arrays_names}
        # exp_dict has as keys the kernel_widths
        for key, val in exp_dict.items():

            for exp_data in val:
                for array_name in arrays_names:
                    # print(array_name == exp_data[2], array_name, exp_data[2])
                    if array_name == exp_data[2]:
                        data_dict[array_name].append(
                            [exp_data[0], exp_data[1]])

        # data_array = np.empty((n_kernels, 3801, 3))
        data_array = np.full((n_kernels, 3801, 3), np.nan)
# kiss
# kiss
# kiss
# Something that works kiss
# improve and check, improve and check

        for key, val in data_dict.items():
            # data_array[:] = np.nan
            for idx, row in enumerate(data_array):
                row[:, 0] = val[idx][0]

                limit = val[idx][1].shape[0]
                # print(limit)

                row[:limit, 1:] = val[idx][1]

            np.save(f"testing/{sdss_name}_metric_{metric}_{key}.npy",
                data_array)

        return data_dict

    if not os.path.exists(exp_file_path):

        print(f'There is no file {exp_file_path}')
        return None

    sdss_name = exp_file_path.split("/")[-1].split("_")[0]
    metric = exp_file_path.split("/")[-1].split("_")[1].strip(".exp")

    # Opening .exp for a spectrum: line[i] = sdss_name, k_width, ftr_selct,
    # around_instance, [(feature, weight), ...]

    with open(exp_file_path, "r") as file:

        ftr_select = []
        around = []
        kernel_widths = {}

        lines = file.readlines()

        for line in lines:
            # convert line to list [sdss_name, k_width,
            # ftr_selct, around_instance, flux_name, exp_weight, repeat...]
            line = self._line_curation(line)

            k_width = line[1] # string
            feature_selection = line[2]
            sample_around_instance = line[3]
            # print(line[1], line[2], line[3])

            # obtaining explanations array for configuration in the
            # explanation of the current line
            line_exp_arr = self._fluxes_weights(line=line[4:])

            # length = np.int(len(line[4:])/2)
            # print(f"length of array: {length}")
            # print(f"the size of the array is: {fluxes_weights.shape}")

            # kernel_widths: dictionary where the key is the k_with and value
            # [k_width, line_exp_arr, ftr_select, around_instance]

            if k_width not in kernel_widths:
                    kernel_widths[k_width] = []
            kernel_widths[k_width].append(
                [np.float(k_width), line_exp_arr,
                f"{feature_selection}_around_{sample_around_instance}"])

        # return kernel_widths

            # Svaing identifiers for the name of the final arrays
            if feature_selection not in ftr_select:
                ftr_select.append(feature_selection)

            if sample_around_instance not in around:
                around.append(sample_around_instance)

            arrays_names = [f"{val[0]}_around_{val[1]}"
                for val in product(ftr_select, around)]

        return kernel_widths, self._get_arrays(exp_dict=kernel_widths,
            arrays_names=arrays_names, sdss_name=sdss_name, metric=metric,
            save=save)

        # return kernel_widths

#
#     if os.path.exists(exp_file_path):
#         # Extracting kernel width
#         # k_width = exp_file_path.split('/')[-1].split('_')[0]
#     else:
#         print(f'There is no file {exp_file_path}')
#         return None
#
#     explanation = None
#
#     with open(f'{exp_file_path}', newline='\n') as file:
#
#         for line in file:
#             explanation = line
#
#     explanation = explanation.split('"')
#     explanation = list(dict.fromkeys(explanation))
#     explanation.remove(',')
#     explanation.remove('')
#     explanation.remove('\r\n')
#
#     n_features = len(explanation)
#     n_values = len(explanation[0].split(','))
#
#     feature_weight = np.empty((n_features, n_values))
#
#
#     if not self.discretize_continuous:
#
#         for feature_idx, tuple in enumerate(explanation):
#
#             tuple = tuple.split(',')
#
#             tuple[0] = np.float(tuple[0].strip("('flux")) - 1.0
#             tuple[1] = np.float(tuple[1].strip(')'))
#
#             feature_weight[feature_idx, :] = np.array(tuple)
#
#     else:
#
#         tuple = tuple.split(',')
#
#         tuple[0] = tuple[0][2:-1]
#         tuple[1] = np.float(tuple[1][:-1])
#
#         if '<' in tuple[0]:
#
#             if len(tuple[0].split('<'))==2:
#                 tuple[0] = np.int(tuple[0].split('<')[0])
#             else:
#                 tuple[0] = np.int(tuple[0].split('<')[1])
#
#         else:
#
#             tuple[0] = np.int(tuple[0].split('>')[0])
#
#         feature_weight[feature_idx, :] = np.array(tuple)
#
#     print(f'numpy array created: [feature, lime_weight]')
#
#     return feature_weight
#
# def analyze_explanation(self, x, exp_file_path):
#
#     if os.path.exists(exp_file_path):
#         exp = self.process_explanation(exp_file_path)
#     else:
#         print(f'There is no file {exp_file_path}')
#         return None
#
#     wave_exp = exp[:, 0].astype(np.int)
#     flx_exp = x[wave_exp]
#     weights_exp = exp[:, 1]
#
#     return wave_exp, flx_exp, weights_exp

################################################################################
    def _get_explainer(self, kernel_width, feature_selection,
        sample_around_instance, x, regressor, sdss_name): explainer =
        dill.dumps(self.Ex_partial(kernel_width, feature_selection,
            sample_around_instance)) return explainer def
    _get_explainers(self):
        params_grid = product( self.k_widths, self.ftrs_slect,
            self.around_instance)
        with mp.Pool(processes=self.n_processes) as pool:
            print('Generating explainers') self.explainers =
            pool.starmap(self._get_explainer, params_grid) size = 0 for p
            in self.explainers:
                x = sys.getsizeof(p)*1e-6 print(f'The size of the
                explainer is: {x:.2f} Mbs')
                # print(dill.loadsp)
                size += x print(f"The total size of the explainers is
            {size:.2f} Mbs")
        return self.explainers def _explain(self, explainer, x,
    regressor, sdss_name):
        print(f"Explaining: {sdss_name}") explainer =
        dill.loads(explainer) regressor = dill.loads(regressor) return
        [sdss_name, explainer.explanation(x, regressor)]
    def explanations(self, x, regressor, sdss_name):
        # list of explanations
        regressor = dill.dumps(regressor) explainers =
        self._get_explainers() params_grid = product(explainers, [x],
        [regressor], [sdss_name]) with
        mp.Pool(processes=self.n_processes) as pool:
            print('Generating explanations') explanations =
            pool.starmap(self._explain, params_grid) size = 0 for p in
            explanations:
                x = sys.getsizeof(p)*1e-6 print(f'The size of the
                explanation is: {x:.2f} Mbs') size += x
            print(f"The total size of the explanations is {size:.2f}
            Mbs")
        return explanations
